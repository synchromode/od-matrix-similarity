# Comparison of Reference-based Trip Probabilities (CoRe-TriP)

Similarity Measure for Origin/Destination (OD) Matrices

SYNCHROMODE project - WP3

## OD Matrix Generation

Two datasets have been utilised:
- the data from **Madrid** extracted from users' cell phone, as Call Detail Records (CDRs);
- the data from **South Holland** extracted from Be-Mobile application, as Floating Car Data (FCD).

For each of them, we provide a specific script located in directory `./odm_generation/`. Before running them, the project directory should be organised as follow.
```
project
├── data
│   ├── south_holland
│   │   ├── raw
│   │   │   ├── M1_YYY1
│   │   │   │   ├── YYY1-M1-01.csv
│   │   │   │   ├── YYY1-M1-02.csv
│   │   │   │   └── ...
│   │   │   ├── M2_YYY1
│   │   │   │   └── ...
│   │   │   └── ...
│   │   ├── basemap_2024_pzh.gpkg
│   │   └── georef-netherlands-postcode-pc4.geojson
│   └── madrid
│       └── ...
├── odm_generation
│   ├── south_holland.py
│   └── madrid.py
└── ...
```

### Madrid

(data not included)
```
python data_generation/madrid.py
```

### South Holland

To generate the OD matrices for South Holland dataset, you must create the directory `./data/south_holland/` beforehand. In the latter must be found the following files:
- `basemap_2024_pzh.gpkg` contains the geometrical description of road segments. Given a segment ID, it makes it possible to map it to a latitude/longitude coordinate.

| segmentID | ... | geometry         |
| :-------: | :-: | :------:         |
| 12345678  | ... | LINESTRING (...) |
| 12345679  | ... | LINESTRING (...) |
| 23456789  | ... | LINESTRING (...) |
| ...       |     | ...              |

- `georef-netherlands-postcode-pc4.geojson` contains the geometrical description of all provinces, communes ("gemeenten" in Dutch), and 4-digit postcode areas in the Netherlands. It makes it possible to map a latitude/longitude coordinate to a postcode.

| prov_name     | gem_name       | pc4_code | ... | geometry           |
| :-----------: | :------------: | :------: | :-: | :------:           |
| Zuid-Holland  | Hoeksche Waard | 3273     | ... | POLYGON (...)      |
| Zuid-Holland  | Dordrecht      | 3311     | ... | POLYGON (...)      |
| Zuid-Holland  | Dordrecht      | 3319     | ... | MULTIPOLYGON (...) |
| Utrecht       | Woerden        | 3481     | ... | POLYGON (...)      |
| ...           | ...            | ...      |     | ...                |

In addition, the dataset of trips must be found in the directory `./data/south_holland/raw/`, as daily files split according to months. For instance, the data of trips from 19/05/2024 should be found in the file `./data/south_holland/raw/05_2024/2024-05-19.csv` (see below how the data should be organised).

| SegmentId | LocalTimeStamp      | TripID |
| :-------: | :-----------------: | :----: |
| 12345678  | 2024-05-19 00:01:00 | 12345  |
| 12345679  | 2024-05-19 00:02:00 | 12345  |
| 23456879  | 2024-05-19 08:30:00 | 23456  |
| ...       | ...                 | ...    |

Finally, in order to generate OD matrices from South Holland region, you must run the following command:
```
python data_generation/south_holland.py
```
It generates daily files split into months into the directory `./data/south_holland/odm/`. Each of the files, whose path is referred to as `./data/south_holland/odm/MM_YYYY/YYYY-MM-DD.npy`, contains a NumPy array of shape `(24,175,175)`, *i.e.*, 24 hourly OD matrices with 175 areas.

## Computing Similarities

Before computing the similarity metric, OD matrices must be generated by following instructions from this [section](#generating-data).

Scripts related to the similarity measure are located into the directory `./similarity/`. 
In order to compute similarities between some OD matrices, you must run the following command:
```
python similarity/compute.py --data=PATH_TO_DATA_DIR [--hourly]
```
where `PATH_TO_DATA_DIR` refers to the directories containing daily OD matrices split according to months. In the context of Madrid or South Holland, it corresponds to the directory `odm/` generated [here](#generating-data), *i.e.*, `./data/[madrid|south_holland]/odm/`. The Pairwise-Daily Approach (PDA) is run by default. To run a Pairwise-Hourly Approach (PHA), generating hourly comparisons, the option `--hourly` should be used. The above command generates a file `sim_coretrip_[daily|hourly].csv` located in directory `./target/` and storing the similarity between each couple of OD matrices from `PATH_TO_DATA_DIR`.

#### Other options

- `--target=PATH_TO_DIR`: Save the generated file into the given directory.
- `--zero-diag`: Ignore trips with a same departure and arrival subareas.
- `--event-beach`: Add weight to beach subareas (specific to South Holland).
- `--event-keukenhof`: Add weight to Lisse subarea (specific to South Holland).
- `--event-weight=WEIGHT`: Use `WEIGHT` to enhance subareas (specific to South Holland, in case a special event is triggered).
- `--event-indices=PATH_TO_FILE` JSON file mapping events to 4-digit postcodes and OD matrix indices. In the case of South Holland, the JSON object should be the following.
```json
{
    "beach": {
        "area": ["2242", "2221", "2225", "2202", "2204"],
        "index": [122, 169, 27, 94, 19]
    },
    "keukenhof": {
        "area": ["2161", "2163"],
        "index": [163, 17]
    }
}
```

#### State-of-the-art techniques

This script offers the possibilty to compute the similarities according to existing techniques, *i.e.*, NLOD and GSSI. For both, a JAX implementation is provided in the file `similarity/measure.py` (along with the implementation of CoRe-TriP). Adding one of the following options will generate the file `sim_[nlod|gssi]_[daily|hourly].csv`.

- `--nlod`: Process the OD matrix similarities using NLOD.
- `--gssi`: Process the OD matrix similarities using GSSI.
- `--gssi-clusters=PATH_TO_FILE`: JSON file containing a dictionary mapping a cluster name to a list of indices (required with the option `--gssi`). In the case of South Holland, the JSON object may be the following (used in the paper).

```json
{
    "Woerden": [0, 7, 44, 85, 90, 91, 114, 130, 147, 157, 158, 173],
    "Nieuwkoop": [1, 24, 42, 63, 72, 73, 86, 99, 140, 174],
    "Katwijk": [2, 20, 27, 37, 45, 59, 141, 169],
    "Voorschoten": [3, 60, 104, 150],
    "Leidschendam-Voorburg": [4, 48, 61, 68, 75, 80, 96, 105, 142, 151, 165, 170],
    "Leiden": [5, 21, 31, 38, 51, 70, 84, 106, 110, 116, 117, 118, 123, 126, 152, 153],
    "Zoetermeer": [6, 14, 25, 47, 55, 64, 65, 69, 89, 100, 101, 124, 128, 133, 139, 145, 167],
    "Bodegraven-Reeuwijk": [8, 41, 78, 129, 138, 146],
    "Haarlemmermeer": [9, 10, 11, 15, 16, 26, 29, 34, 49, 50, 57, 58, 66, 74, 79, 81, 92, 93, 102, 108, 119, 120, 134, 135, 136, 137, 148, 159, 160, 161, 162, 168],
    "Alphen aan den Rijn": [12, 13, 22, 23, 33, 43, 46, 62, 71, 98, 107, 113, 144, 156, 171, 172],
    "Lisse": [17, 67, 163],
    "Teylingen": [18, 83, 115, 125, 143, 166],
    "Noordwijk": [19, 30, 35, 36, 87, 94, 109],
    "Kaag en Braassem": [28, 40, 76, 77, 88, 103, 111, 112, 127, 132],
    "Zoeterwoude": [32, 56, 154],
    "Oegstgeest": [39, 52, 155],
    "Leiderdorp": [53, 54, 97],
    "Hillegom": [82, 121],
    "Wassenaar": [95, 122, 131, 149, 164]
}
```

### Normalisation

To normalise the obtained similarities with the PDA or PHA, you must run the following command:
```
python similarity/normalise.py --source=PATH_TO_FILE [--hourly]
```
where `PATH_TO_FILE` refers to the CSV file generated [here](#computing-similarity), *i.e.* containing the similarity between each couple of OD matrices from the dataset.
By default, the similarities are assumed to be generated with PDA. In order to gather hourly similarities (generated with PHA) into daily comparisons, the option `--hourly` should be used.
The above command generates a CSV file located in the same directory as the source file, adding the prefix `"norm_"` in its name.

#### Other options

- `--target=PATH_TO_FILE`: Save the generated file in the given path.

## Visualising Similarities

Several scripts are provided to view the obtained similarities. They have been used to generate the figures used in the paper.

### Boxplot

To view the distribution of similarities between each day of the week, you must run the following command:
```
python similarity/boxplot.py --source=PATH_TO_FILE [--dissimilarity]
```
where `PATH_TO_FILE` refers to the CSV file generated [here](#normalisation), *i.e.* containing the normalised similarity between each couple of OD matrices from the dataset.
In case the measure is a dissimilarity, *i.e.*, the greater value the lower proximity between OD matrices, the option `--dissimilarity` should be used.
The above command generates a PNG file located in the same directory as the source file, replacing the prefix `"norm_sim"` by `"boxplot"` in its name.

#### Other options

- `--target=PATH_TO_FILE`: Save the generated file into the given path.
- `--fontsize=SIZE`: Specify the font size of labels, legends and titles from the plot.

### Heatmap

To view the similarities between each couple of days within the whole period, you must run the following command:
```
python similarity/heatmap.py --source=PATH_TO_FILE [--dissimilarity]
```
where `PATH_TO_FILE` refers to the CSV file generated [here](#normalisation), *i.e.* containing the normalised similarity between each couple of OD matrices from the dataset.
In case the measure is a dissimilarity, *i.e.*, the greater value the lower proximity between OD matrices, the option `--dissimilarity` should be used.
The above command generates a PNG file located in the same directory as the source file, replacing the prefix `"norm_sim"` by `"heatmap"` in its name.

#### Other options

- `--target=PATH_TO_FILE`: Save the generated file into the given path.

### Generate GEXF file

To visualise the graph of similarities, you must run the following command to generate a GEXF file to be used as an input to Gephi software:
```
python similarity/generate_gexf.py --data=PATH_TO_FILE [--dissimilarity]
```
where `PATH_TO_FILE` refers to the CSV file generated [here](#normalisation), *i.e.* containing the normalised similarity between each couple of OD matrices from the dataset.
In case the measure is a dissimilarity, *i.e.*, the greater value the lower proximity between OD matrices, the option `--dissimilarity` should be used.
The above command generates a PNG file located in the same directory as the source file, replacing the prefix `"norm_sim"` by `"graph"` in its name.

#### Other options

- `--target=PATH_TO_FILE`: Save the generated file into the given path.
- `--weather=PATH_TO_FILE`: Add two node attributes: the weather condition and the temperature obtained from the given CSV file.
- `--visitors=PATH_TO_FILE`: Add a node attribute indicating the number of Keukenhof visitors from the given CSV file.
- `--keukenhof`: Add a node attribute indicating whether Keukenhof was open at the corresponding day.
- `--prune`: Remove edges whose corresponding similarity is considered as an outlier.

### Comparison

To compare the similarities obtained from different measures, you must run the following command:
```
python similarity/stats.py --source=PATH_TO_FILE
```
where `PATH_TO_FILE` refers to a JSON file describing the measures to show on the figure. That file should contain a JSON object as exampled below. The above command generates a PNG file located in the same directory as the source file.
```json
[
    {
        "name": "CoRe-TriP (PHA)",
        "location": "target/norm_sim_coretrip_hourly.csv",
        "dissimilarity": true
    },
    {
        "name": "NLOD (PDA)",
        "location": "target/norm_sim_nlod_daily.csv",
        "dissimilarity": true
    },
    {
        "name": "GSSI (PHA)",
        "location": "target/norm_sim_gssi_hourly.csv",
        "dissimilarity": false
    }
]
```


#### Other options

- `--target=PATH_TO_FILE`: Save the generated file into the given path.
- `--year`: Process the comparison according to months of the year instead of days of the week.
- `--fontsize=SIZE`: Specify the font size of labels, legends and titles from the plot.
- `--markersize=SIZE`: Specify the dot size from the plot.
- `--linewidth=WIDTH`: Specify the line width from the plot.
- `--stdalpha=RATIO`: Specify the transparency of the area depicting standard deviation.

## Computing Similarity from URL

In order to compute the similarity, given an URL to a ZIP file containing the OD matrices, you must run the following command:
```
python compute_similarity_from_url.py --source=URL_TO_ZIP_FILE [--google-drive] [--hourly]
```
where `URL_TO_ZIP_FILE` is an URL pointing to the ZIP file to download. In case that file is located on Google Drive, the option `--google-drive` should be used and `URL_TO_ZIP_FILE` refers to the share link of the file. If you want to make an hourly comparison (instead of daily by default), you must use the option `--hourly`.

### Input

The ZIP file should contain the OD matrices into daily files named `YYYY-MM-DD.npy`. Each of those files contains a NumPy array of dimension 24xNxN, where N is the number of subareas. They can be organised within subdirectories in any way, it does not affect the effective functioning of the script.

### Output

This script creates a JSON file consisting of the day-to-day comparison of OD matrices. That file contains a pandas database organised as follow:
| day1 | month1 | year1 | day2 | month2 | year2 | similarity |
| :--: | :----: | :---: | :--: | :----: | :---: | :--------: |
| 1    | 3      | 2024  | 1    | 3      | 2024  | 0.0        |
| 1    | 3      | 2024  | 2    | 3      | 2024  | 0.4        |
| 1    | 3      | 2024  | 3    | 3      | 2024  | 0.6        |
| ...  | ...    | ...   | ...  | ...    | ...   | ...        |

In case a hourly comparison has been chosen (with the option `--hourly`), the data is gathered into daily data before being saved in the JSON file.

### Other options

- `--target=PATH_TO_TARGET_DIR`: Save the generated file into the directory located in `PATH_TO_TARGET_DIR`.
- `--filename=FILENAME`: Change the name of the generated JSON file into `FILENAME`.
- `--zero-diag`: Ignore trips with a same departure and arrival subareas.
